
# Changing Tire Assistant â€“ Computer Vision & NLP Project

[![Python Version](https://img.shields.io/badge/python-3.x-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](./LICENSE)


**ğŸš§ Project Status: Under Development ğŸš§**

---

## ğŸ“– Overview
This assistant leverages real-time computer vision and NLP to guide users through changing a flat tire using an egocentric (chest-mounted) camera. 

The assistant detects tools, tracks task progress, and provides interactive, step-by-step visual and voice instructions for changing a vehicle tire.

---

## ğŸ” System Features
- **Real-Time Tool Detection**:
  - Identifies car jack, wheel wrench, etc.
- **Action Recognition**:
  - Tracks task progression like loosening nuts, jacking the car, replacing the wheel, etc.
- **Voice Assistant**:
  - Responds to user queries such as "What's next?"
- **Edge-Friendly Pipeline**:
  - Designed for deployment on mobile or embedded systems with minimal latency.

---

## ğŸ“‚ Project Structure
```              
â”œâ”€â”€ action_recognition/                 # Trained YOLO/Action Recognition/Voice Assistant models
â”œâ”€â”€ object_detection/                  # Utility scripts for preprocessing, inference
â”œâ”€â”€ requirements.txt        # Python dependencies           # This file           
```

---

## ğŸ§  Models Used
- **Object Detection**: YOLOv8 fine-tuned on tire-change-specific tools and components
- **Action Recognition**: We are trying different models SlowFast , TSM , TimeDistributed EfficientNetB0
- **Voice Assistant**: Whisper-based STT with a custom NLP pipeline for contextual understanding

---

## ğŸ“Š Data
We collected and curated a custom dataset specifically for the tire change domain:

### Data Collection Methodology
- **Primary Source**: Self-collected footage changing two tires on a Renault Megane 2, recorded with Samsung A50 smartphones from chest-mounted positions
- **Secondary Source**: Curated YouTube videos showing different tire change scenarios and vehicle types
- **Annotation Process**: Manual annotation of action segments and tool detection bounding boxes

### Dataset Structure
The data directory contains the following action classes:
```
data/
â”œâ”€â”€ lower_car/             # Videos/frames of lowering the car from the jack
â”œâ”€â”€ lift_car_with_jack/    # Videos/frames of raising the car with jack
â”œâ”€â”€ tighten_bolts/         # Videos/frames of final bolt tightening with wrench
â”œâ”€â”€ initial_wrench_tighten/# Videos/frames of initial wrench positioning
â”œâ”€â”€ place_spare_tire/      # Videos/frames of positioning the spare tire
â”œâ”€â”€ remove_tire/           # Videos/frames of removing the flat tire
â”œâ”€â”€ hand_tighten_bolts/    # Videos/frames of hand-tightening bolts
â”œâ”€â”€ loosen_bolts/          # Videos/frames of loosening wheel bolts
â”œâ”€â”€ remove_bolts/          # Videos/frames of removing wheel bolts
â”œâ”€â”€ labels.csv             # Action timestamps and class annotations
â””â”€â”€ README.txt             # Dataset documentation
```

Each action class directory contains video clips used for model training and validation.

https://github.com/user-attachments/assets/6d6bef7f-5d31-4b78-b57b-93b3566c5007


## ğŸ‘¨â€ğŸ’» Authors
- **SOHAIB DAOUDI** â€“ [soh.daoudi@gmail.com](mailto:soh.daoudi@gmail.com)
- **MAROUANE MAJIDI** â€“ [majidi.marouane0@gmail.com](mailto:majidi.marouane0@gmail.com)

---

## ğŸ“œ License
This project is licensed under the [MIT License](https://opensource.org/licenses/MIT). See the `LICENSE` file for more details.

